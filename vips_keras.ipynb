{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=256\n",
    "overl=0.5\n",
    "epochs=3\n",
    "modelname=\"model3_256\"\n",
    "batchsize=10\n",
    "training=True\n",
    "base='/home/john/GIT/VipsML'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import Sequence\n",
    "import pyvips as Vips\n",
    "from random import shuffle, choice\n",
    "from numpy import rot90, flip, frombuffer, uint8, asarray, squeeze\n",
    "from math import ceil, floor\n",
    "from functools import reduce\n",
    "\n",
    "class SegNetImage(Sequence):    \n",
    "    \"\"\"Generator class to be fed to a keras fit-function.\"\"\"\n",
    "\n",
    "    def __init__(self,imagePath,maskpath=None,frame=256,overlay=0.0, batchSize=10):\n",
    "        \"\"\"Args:\n",
    "            imagePath: Path to original image.\n",
    "            maskpath: Path to image masks, None if not training.\n",
    "            frame: Frame size (x and y dim)\n",
    "            overlay: How much overlay to keep between each piece of the image.\n",
    "            batchSize: Batchsize for feeding into CNN.\"\"\"\n",
    "        \n",
    "        self.orig=Vips.Image.new_from_file(imagePath)        \n",
    "        h,w,d = self.orig.width, self.orig.height, self.orig.bands        \n",
    "        self.origShape = (w,h,d)\n",
    "        self.frame=frame\n",
    "        self.overlay=round(self.frame*overlay)\n",
    "        self.step = self.frame-self.overlay        \n",
    "        self.batchSize=batchSize                \n",
    "        \n",
    "        #The last step will cover a whole frame\n",
    "        self.x_frames=ceil((w-(self.frame-self.step))/(self.step))\n",
    "        self.y_frames=ceil((h-(self.frame-self.step))/(self.step))        \n",
    "        self.total_frames=self.x_frames*self.y_frames\n",
    "        \n",
    "        # Fix padding \n",
    "        _w = ceil(self.x_frames*self.step)+(self.frame-self.step)\n",
    "        _h = ceil(self.y_frames*self.step)+(self.frame-self.step)\n",
    "        self.embeddedShape = (_w, _h, d)\n",
    "        self.orig=self.orig.embed(0,0,_w,_h,extend='white')    \n",
    "                \n",
    "        if maskpath == None:\n",
    "            self.training=False\n",
    "        else:\n",
    "            self.training=True\n",
    "            self.initMask(maskpath)\n",
    "            self.frame_order = list(range(self.total_frames))\n",
    "            # The fit function will randomize the batch order,\n",
    "            # but not the individual datasets inside each batch:\n",
    "            shuffle(self.frame_order)\n",
    "        \n",
    "    def initMask(self,maskpath):\n",
    "        self.mask=Vips.Image.new_from_file(maskpath)\n",
    "        self.mask=self.mask.embed(0,0,self.embeddedShape[0],self.embeddedShape[1],extend='black')\n",
    "        # We need a binary class matrix for training.\n",
    "        # We could use keras.utils.to_categorical downstream instead.\n",
    "        self.hist=self.mask.hist_find()\n",
    "        self.featureN = self.hist.width\n",
    "        features=list(range(self.featureN))\n",
    "        expanded = None\n",
    "        for f in features:\n",
    "            if expanded:\n",
    "                expanded=expanded.bandjoin(self.mask==f)\n",
    "            else:\n",
    "                expanded = self.mask==f\n",
    "        self.mask=expanded  \n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(ceil(self.total_frames/self.batchSize))\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        # the keras.utils.Sequence expects one batch upon requesting an item\n",
    "        start = index*self.batchSize\n",
    "        end = min((index+1)*(self.batchSize),self.total_frames)\n",
    "        if self.training:\n",
    "            origs = []\n",
    "            masks = []\n",
    "            # We iterate one by one to assign random rotation and flipping\n",
    "            # to both image and mask\n",
    "            for i in self.frame_order[start:end]:\n",
    "                rot=choice(range(4))\n",
    "                flippage=choice(range(2))==1\n",
    "                origs += [self.getSingleItem(i,rot,flippage)]\n",
    "                # Output vector is expected to be 1D (could be fixed in the model definition):\n",
    "                masks += [self.getMask(i,rot,flippage).reshape((self.frame*self.frame,self.featureN))]\n",
    "            return asarray(origs),asarray(masks).astype(float)\n",
    "        else:\n",
    "            return asarray([self.getSingleItem(i) for i in range(start,end)])\n",
    "    \n",
    "    def getSingleItem(self,index,rot=0,flp=False):\n",
    "        rotations=[lambda x: x,lambda x: x.rot90(), lambda x: x.rot180(), lambda x: x.rot270()]\n",
    "        y = floor(index/self.x_frames)\n",
    "        x = index % self.x_frames\n",
    "        x_px = x*(self.step)\n",
    "        y_px = y*(self.step)\n",
    "        o=self.getImageAt(x_px, y_px, self.frame)\n",
    "        o=rotations[rot](o)\n",
    "        if flp:\n",
    "            o=o.fliphor()\n",
    "        return self.toNp(o)\n",
    "        \n",
    "    def getMask(self,index,rot=0,flp=False):\n",
    "        rotations=[lambda x: x,lambda x: x.rot90(), lambda x: x.rot180(), lambda x: x.rot270()]\n",
    "        y = floor(index/self.x_frames)\n",
    "        x = index % self.x_frames\n",
    "        x_px = x*(self.step)\n",
    "        y_px = y*(self.step)\n",
    "        o=self.getImageAt(x_px,y_px,self.frame,im=self.mask)\n",
    "        o=rotations[rot](o)\n",
    "        if flp:\n",
    "            o=o.fliphor()\n",
    "        return self.toNp(o)\n",
    "\n",
    "    def getShape(self):\n",
    "        return (self.frame, self.frame, 3)\n",
    "        \n",
    "    def toNp(self,im):\n",
    "        return frombuffer(im.write_to_memory(), dtype=uint8).reshape(im.width, im.height, im.bands)\n",
    "     \n",
    "    def getBoxFrom(self,x,y,w):\n",
    "        return (x,y,x+w,y+w)\n",
    "\n",
    "    def getImageAt(self,x,y,w,im=None):\n",
    "        if im is None:\n",
    "          im=self.orig\n",
    "        return im.crop(x,y,w,w)\n",
    "\n",
    "    def setBatchSize(self,n):\n",
    "        self.batchSize=n\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # re-randomize upon finishing an epoch\n",
    "        shuffle(self.frame_order)\n",
    "\n",
    "class MultiSegNetImage(Sequence):\n",
    "    def __init__(self,origs,masks=None,frame=256,overlay=0.0, batchSize=10):\n",
    "        self.frame=frame\n",
    "        self.overlay=overlay\n",
    "        self.batchSize=batchSize\n",
    "        self.training = masks!=None\n",
    "        self.images = [SegNetImage(origs[i],masks[i] if self.training else None,frame,overlay,batchSize) for i in range(len(origs))]\n",
    "        self.indices = reduce(lambda acc, val: acc+[(val,i) for i in range(self.images[val].total_frames)],range(len(self.images)),[])\n",
    "        shuffle(self.indices)\n",
    "    \n",
    "    def getShape(self):\n",
    "        \"\"\" Peek ahead at first image in stack\"\"\"\n",
    "        return self.images[0].getShape()\n",
    "    \n",
    "    def totalItems(self):\n",
    "        \"\"\" Total number of items \"\"\"\n",
    "        return len(self.indices)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\" Number of batches, not items \"\"\"\n",
    "        return int(ceil(self.totalItems()/self.batchSize))\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \"\"\" One batch, not one item \"\"\"\n",
    "        start = index*self.batchSize\n",
    "        end = min((index+1)*(self.batchSize),self.totalItems())\n",
    "        if self.training:\n",
    "            origs = []\n",
    "            masks = []\n",
    "            # We iterate one by one to assign (same) random rotation\n",
    "            # and flipping to both image and mask\n",
    "            for entry in self.indices[start:end]:\n",
    "                imageN,itemN = entry\n",
    "                image=self.images[imageN]\n",
    "                rot=choice(range(4))\n",
    "                flippage=choice(range(2))==1\n",
    "                origs += [image.getSingleItem(itemN,rot,flippage)]\n",
    "                # Output vector is expected to be 1D (could be fixed in the model definition):\n",
    "                masks += [image.getMask(itemN,rot,flippage).reshape((image.frame*image.frame,image.featureN))]\n",
    "            return asarray(origs),asarray(masks).astype(float)\n",
    "        else:\n",
    "            return asarray([self.images[i].getSingleItem(n) for i,n in indices[start:end]])\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        # re-randomize upon finishing an epoch\n",
    "        shuffle(self.indices)\n",
    "            \n",
    "\n",
    "#K.set_floatx('float32')\n",
    "#K.set_epsilon(1e-7) \n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "\n",
    "\n",
    "# Creds to ykamikawa/tf-keras-SegNet\n",
    "class MaxPoolingWithArgmax2D(Layer):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            pool_size=(2, 2),\n",
    "            strides=(2, 2),\n",
    "            padding='same',\n",
    "            **kwargs):\n",
    "        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n",
    "        self.padding = padding\n",
    "        self.pool_size = pool_size\n",
    "        self.strides = strides\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        padding = self.padding\n",
    "        pool_size = self.pool_size\n",
    "        strides = self.strides\n",
    "        if K.backend() == 'tensorflow':\n",
    "            ksize = [1, pool_size[0], pool_size[1], 1]\n",
    "            padding = padding.upper()\n",
    "            strides = [1, strides[0], strides[1], 1]\n",
    "            output, argmax = K.tf.nn.max_pool_with_argmax(\n",
    "                    inputs,\n",
    "                    ksize=ksize,\n",
    "                    strides=strides,\n",
    "                    padding=padding)\n",
    "        else:\n",
    "            errmsg = '{} backend is not supported for layer {}'.format(\n",
    "                    K.backend(), type(self).__name__)\n",
    "            raise NotImplementedError(errmsg)\n",
    "        argmax = K.cast(argmax, K.floatx())\n",
    "        return [output, argmax]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        ratio = (1, 2, 2, 1)\n",
    "        output_shape = [\n",
    "                dim//ratio[idx]\n",
    "                if dim is not None else None\n",
    "                for idx, dim in enumerate(input_shape)]\n",
    "        output_shape = tuple(output_shape)\n",
    "        return [output_shape, output_shape]\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return 2 * [None]\n",
    "\n",
    "\n",
    "class MaxUnpooling2D(Layer):\n",
    "    def __init__(self, size=(2, 2), **kwargs):\n",
    "        super(MaxUnpooling2D, self).__init__(**kwargs)\n",
    "        self.size = size\n",
    "\n",
    "    def call(self, inputs, output_shape=None):\n",
    "        updates, mask = inputs[0], inputs[1]\n",
    "        with K.tf.variable_scope(self.name):\n",
    "            mask = K.cast(mask, 'int32')\n",
    "            input_shape = K.tf.shape(updates, out_type='int32')\n",
    "            #  calculation new shape\n",
    "            if output_shape is None:\n",
    "                output_shape = (\n",
    "                        input_shape[0],\n",
    "                        input_shape[1]*self.size[0],\n",
    "                        input_shape[2]*self.size[1],\n",
    "                        input_shape[3])\n",
    "            self.output_shape1 = output_shape\n",
    "\n",
    "            # calculation indices for batch, height, width and feature maps\n",
    "            one_like_mask = K.ones_like(mask, dtype='int32')\n",
    "            batch_shape = K.concatenate(\n",
    "                    [[input_shape[0]], [1], [1], [1]],\n",
    "                    axis=0)\n",
    "            batch_range = K.reshape(\n",
    "                    K.tf.range(output_shape[0], dtype='int32'),\n",
    "                    shape=batch_shape)\n",
    "            b = one_like_mask * batch_range\n",
    "            y = mask // (output_shape[2] * output_shape[3])\n",
    "            x = (mask // output_shape[3]) % output_shape[2]\n",
    "            feature_range = K.tf.range(output_shape[3], dtype='int32')\n",
    "            f = one_like_mask * feature_range\n",
    "\n",
    "            # transpose indices & reshape update values to one dimension\n",
    "            updates_size = K.tf.size(updates)\n",
    "            indices = K.transpose(K.reshape(\n",
    "                K.stack([b, y, x, f]),\n",
    "                [4, updates_size]))\n",
    "            values = K.reshape(updates, [updates_size])\n",
    "            ret = K.tf.scatter_nd(indices, values, output_shape)\n",
    "            return ret\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        mask_shape = input_shape[1]\n",
    "        return (\n",
    "                mask_shape[0],\n",
    "                mask_shape[1]*self.size[0],\n",
    "                mask_shape[2]*self.size[1],\n",
    "                mask_shape[3]\n",
    "                )\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Activation, Reshape\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "#from layers import MaxPoolingWithArgmax2D, MaxUnpooling2D\n",
    "\n",
    "\n",
    "def segnet(\n",
    "        input_shape,\n",
    "        n_labels,\n",
    "        kernel=3,\n",
    "        pool_size=(2, 2),\n",
    "        output_mode=\"softmax\"):\n",
    "    # encoder\n",
    "    inputs = Input(batch_shape=(None,)+input_shape)\n",
    "\n",
    "    conv_1 = Convolution2D(64, (kernel, kernel), padding=\"same\")(inputs)\n",
    "    conv_1 = BatchNormalization()(conv_1)\n",
    "    conv_1 = Activation(\"relu\")(conv_1)\n",
    "    conv_2 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_1)\n",
    "    conv_2 = BatchNormalization()(conv_2)\n",
    "    conv_2 = Activation(\"relu\")(conv_2)\n",
    "\n",
    "    pool_1, mask_1 = MaxPoolingWithArgmax2D(pool_size)(conv_2)\n",
    "\n",
    "    conv_3 = Convolution2D(128, (kernel, kernel), padding=\"same\")(pool_1)\n",
    "    conv_3 = BatchNormalization()(conv_3)\n",
    "    conv_3 = Activation(\"relu\")(conv_3)\n",
    "    conv_4 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_3)\n",
    "    conv_4 = BatchNormalization()(conv_4)\n",
    "    conv_4 = Activation(\"relu\")(conv_4)\n",
    "\n",
    "    pool_2, mask_2 = MaxPoolingWithArgmax2D(pool_size)(conv_4)\n",
    "\n",
    "    conv_5 = Convolution2D(256, (kernel, kernel), padding=\"same\")(pool_2)\n",
    "    conv_5 = BatchNormalization()(conv_5)\n",
    "    conv_5 = Activation(\"relu\")(conv_5)\n",
    "    conv_6 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_5)\n",
    "    conv_6 = BatchNormalization()(conv_6)\n",
    "    conv_6 = Activation(\"relu\")(conv_6)\n",
    "    conv_7 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_6)\n",
    "    conv_7 = BatchNormalization()(conv_7)\n",
    "    conv_7 = Activation(\"relu\")(conv_7)\n",
    "\n",
    "    pool_3, mask_3 = MaxPoolingWithArgmax2D(pool_size)(conv_7)\n",
    "\n",
    "    conv_8 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_3)\n",
    "    conv_8 = BatchNormalization()(conv_8)\n",
    "    conv_8 = Activation(\"relu\")(conv_8)\n",
    "    conv_9 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_8)\n",
    "    conv_9 = BatchNormalization()(conv_9)\n",
    "    conv_9 = Activation(\"relu\")(conv_9)\n",
    "    conv_10 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_9)\n",
    "    conv_10 = BatchNormalization()(conv_10)\n",
    "    conv_10 = Activation(\"relu\")(conv_10)\n",
    "\n",
    "    pool_4, mask_4 = MaxPoolingWithArgmax2D(pool_size)(conv_10)\n",
    "\n",
    "    conv_11 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_4)\n",
    "    conv_11 = BatchNormalization()(conv_11)\n",
    "    conv_11 = Activation(\"relu\")(conv_11)\n",
    "    conv_12 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_11)\n",
    "    conv_12 = BatchNormalization()(conv_12)\n",
    "    conv_12 = Activation(\"relu\")(conv_12)\n",
    "    conv_13 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_12)\n",
    "    conv_13 = BatchNormalization()(conv_13)\n",
    "    conv_13 = Activation(\"relu\")(conv_13)\n",
    "\n",
    "    pool_5, mask_5 = MaxPoolingWithArgmax2D(pool_size)(conv_13)\n",
    "    print(\"Build encoder done..\")\n",
    "\n",
    "    # decoder\n",
    "\n",
    "    unpool_1 = MaxUnpooling2D(pool_size)([pool_5, mask_5])\n",
    "\n",
    "    conv_14 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_1)\n",
    "    conv_14 = BatchNormalization()(conv_14)\n",
    "    conv_14 = Activation(\"relu\")(conv_14)\n",
    "    conv_15 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_14)\n",
    "    conv_15 = BatchNormalization()(conv_15)\n",
    "    conv_15 = Activation(\"relu\")(conv_15)\n",
    "    conv_16 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_15)\n",
    "    conv_16 = BatchNormalization()(conv_16)\n",
    "    conv_16 = Activation(\"relu\")(conv_16)\n",
    "\n",
    "    unpool_2 = MaxUnpooling2D(pool_size)([conv_16, mask_4])\n",
    "\n",
    "    conv_17 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_2)\n",
    "    conv_17 = BatchNormalization()(conv_17)\n",
    "    conv_17 = Activation(\"relu\")(conv_17)\n",
    "    conv_18 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_17)\n",
    "    conv_18 = BatchNormalization()(conv_18)\n",
    "    conv_18 = Activation(\"relu\")(conv_18)\n",
    "    conv_19 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_18)\n",
    "    conv_19 = BatchNormalization()(conv_19)\n",
    "    conv_19 = Activation(\"relu\")(conv_19)\n",
    "\n",
    "    unpool_3 = MaxUnpooling2D(pool_size)([conv_19, mask_3])\n",
    "\n",
    "    conv_20 = Convolution2D(256, (kernel, kernel), padding=\"same\")(unpool_3)\n",
    "    conv_20 = BatchNormalization()(conv_20)\n",
    "    conv_20 = Activation(\"relu\")(conv_20)\n",
    "    conv_21 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_20)\n",
    "    conv_21 = BatchNormalization()(conv_21)\n",
    "    conv_21 = Activation(\"relu\")(conv_21)\n",
    "    conv_22 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_21)\n",
    "    conv_22 = BatchNormalization()(conv_22)\n",
    "    conv_22 = Activation(\"relu\")(conv_22)\n",
    "\n",
    "    unpool_4 = MaxUnpooling2D(pool_size)([conv_22, mask_2])\n",
    "\n",
    "    conv_23 = Convolution2D(128, (kernel, kernel), padding=\"same\")(unpool_4)\n",
    "    conv_23 = BatchNormalization()(conv_23)\n",
    "    conv_23 = Activation(\"relu\")(conv_23)\n",
    "    conv_24 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_23)\n",
    "    conv_24 = BatchNormalization()(conv_24)\n",
    "    conv_24 = Activation(\"relu\")(conv_24)\n",
    "\n",
    "    unpool_5 = MaxUnpooling2D(pool_size)([conv_24, mask_1])\n",
    "\n",
    "    conv_25 = Convolution2D(64, (kernel, kernel), padding=\"same\")(unpool_5)\n",
    "    conv_25 = BatchNormalization()(conv_25)\n",
    "    conv_25 = Activation(\"relu\",name='25')(conv_25)\n",
    "\n",
    "    conv_26 = Convolution2D(n_labels, (1, 1), padding=\"valid\")(conv_25)\n",
    "    conv_26 = BatchNormalization()(conv_26)\n",
    "    conv_26 = Reshape(\n",
    "            (input_shape[0] * input_shape[1], n_labels),\n",
    "            input_shape=(input_shape[0], input_shape[1], n_labels))(conv_26)\n",
    "\n",
    "    outputs = Activation(output_mode,name='out')(conv_26)\n",
    "    print(\"Build decoder done..\")\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"SegNet\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/john/GIT/VipsML/VipsML/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Build encoder done..\n",
      "Build decoder done..\n",
      "WARNING:tensorflow:From /home/john/GIT/VipsML/VipsML/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/john/GIT/VipsML/VipsML/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#from keras.optimizers import SGD\n",
    "#INIT_LR = (10**(-3))*1.5\n",
    "#opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "s=MultiSegNetImage([base+'/00-orig.tif'],masks=[base+'/00-mask.tif'],frame=size,overlay=overl,batchSize=batchsize)\n",
    "\n",
    "model=segnet(\n",
    "        s.getShape(),\n",
    "        5,\n",
    "        kernel=3,\n",
    "        pool_size=(2, 2))\n",
    "\n",
    "if training:\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='sgd',\n",
    "        metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "    H = model.fit_generator(s,epochs=epochs)\n",
    "    model.save(base+\"/\" + modelname)\n",
    "\n",
    "if not training:\n",
    "    model.load_weights(base+\"/\" +modelname)\n",
    "    from matplotlib import pyplot as plt\n",
    "    import numpy as np\n",
    "    from random import shuffle\n",
    "\n",
    "    plt.figure(figsize = (50,20))\n",
    "    rs=list(range(len(s)))\n",
    "    shuffle(rs)\n",
    "    si=20\n",
    "    f, axarr = plt.subplots(si,3,figsize=(20,100))\n",
    "\n",
    "    for i in range(si):\n",
    "      dta2=model.predict(asarray([s.images[0].getSingleItem(rs[i])]))\n",
    "      dta2=squeeze(dta2,axis=0)\n",
    "      dta2=dta2.reshape((size,size,5))\n",
    "\n",
    "      axarr[i][0].imshow(np.argmax(dta2,axis=2),vmax=4,cmap='hot')\n",
    "\n",
    "      axarr[i][1].imshow(s.images[0].getSingleItem(rs[i]))\n",
    "      axarr[i][2].imshow(np.argmax(s.images[0].getMask(rs[i]),axis=2),vmax=4,cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
